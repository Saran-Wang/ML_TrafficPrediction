{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18259,
     "status": "ok",
     "timestamp": 1651097279868,
     "user": {
      "displayName": "Shiyuan Wang",
      "userId": "08549609244146929949"
     },
     "user_tz": 300
    },
    "id": "Tjkd_sF_mzuc",
    "outputId": "581a8daa-f8d3-42c5-8706-f72e03dc141b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4ocXa_anAuG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path_of_this_jupyer_notebook_without_filename=r'/content/gdrive/MyDrive/CEE498_Project'\n",
    "os.chdir(path_of_this_jupyer_notebook_without_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40712,
     "status": "ok",
     "timestamp": 1651097326954,
     "user": {
      "displayName": "Shiyuan Wang",
      "userId": "08549609244146929949"
     },
     "user_tz": 300
    },
    "id": "Z2ncyV01nBeo",
    "outputId": "fbb10d6e-c84a-4aaf-ead0-a0b197ea4bc6"
   },
   "outputs": [],
   "source": [
    "!unzip \"/content/gdrive/MyDrive/CEE498_Project/training.zip\" -d \"/content\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yy59nF0en4AZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WU07hWzToEjq"
   },
   "source": [
    "### Example of lowering resolution of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4634,
     "status": "ok",
     "timestamp": 1651097656788,
     "user": {
      "displayName": "Shiyuan Wang",
      "userId": "08549609244146929949"
     },
     "user_tz": 300
    },
    "id": "Dqab7_ZBbRQt",
    "outputId": "0c7574c8-23d7-47b6-830d-85b6d25883b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first move axis (288, 8, 495, 436)\n",
      "after max pooling of volume torch.Size([288, 4, 70, 72])\n",
      "after min pooling of speed torch.Size([288, 4, 70, 72])\n",
      "final output shape (288, 70, 72, 8)\n"
     ]
    }
   ],
   "source": [
    "# Reduce the number of pixels from 495*436 to 70*72\n",
    "# resolution from 100m*100m to around 750m * 675m\n",
    "f = np.array(h5py.File('/content/training/2019-06-06_CHICAGO_8ch.h5','r')['array']) # original shape (288, 495, 436, 8)\n",
    "f_mov_array = np.moveaxis((f),-1,1) # to shape(288, 8, 495, 436)\n",
    "print('first move axis',f_mov_array.shape)\n",
    "\n",
    "f_v = f_mov_array[:,[0,2,4,6],:,:] # index by volume\n",
    "f_s = f_mov_array[:,[1,3,5,7],:,:] # index by speed\n",
    "\n",
    "m = nn.MaxPool2d((7,6)) \n",
    "\n",
    "# Max volume\n",
    "f_v = torch.from_numpy(f_v).float() # numpy to torch\n",
    "output_v = m(f_v) # to shape(288, 4, 70, 72)\n",
    "print('after max pooling of volume',output_v.shape)\n",
    "\n",
    "# Max (0,Min(speed))\n",
    "f_s = torch.from_numpy(f_s).float() # numpy to torch\n",
    "f_s = f_s.where(f_s!=0, torch.tensor(256.0)) * (-1)\n",
    "output_s = m(f_s) * (-1) # to shape(288, 4, 70, 72)\n",
    "output_s = output_s.where(output_s!=256, torch.tensor(0.0))\n",
    "print('after min pooling of speed',output_s.shape)\n",
    "\n",
    "output_v = np.moveaxis(output_v.numpy(),1,-1) \n",
    "output_s = np.moveaxis(output_s.numpy(),1,-1) \n",
    "output_final = np.concatenate((output_v,output_s),axis=-1) # to shape(288, 70, 72, 8)\n",
    "print('final output shape',output_final.shape)\n",
    "# # output_final = torch.from_numpy(output_final).float() # numpy to torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQgbL-7MiH7W"
   },
   "outputs": [],
   "source": [
    "# write into h5 file\n",
    "file = h5py.File('test.h5','w')\n",
    "file.create_dataset('data', data = output_final)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOLfNlJ3jei8"
   },
   "outputs": [],
   "source": [
    "aa = np.array(h5py.File('/content/gdrive/MyDrive/CEE498_Project/test.h5','r')['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNkHiWCHo25F"
   },
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBq4jI9-o5oG"
   },
   "source": [
    "\n",
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GrCV7CQakru"
   },
   "source": [
    "## Train data *2019-01-02 -- 2019-05-31*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9861,
     "status": "ok",
     "timestamp": 1651099948483,
     "user": {
      "displayName": "Shiyuan Wang",
      "userId": "08549609244146929949"
     },
     "user_tz": 300
    },
    "id": "F8IslDDY7UaE",
    "outputId": "710a5277-628a-402b-8fe9-252c92f664f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (288, 70, 72, 8))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract file name from 2019-01-02\n",
    "train_file= [sorted(os.listdir(r'/content/training'))[0][:10]] \n",
    "\n",
    "# extract matrices from 2019-01-02\n",
    "f = np.array(h5py.File('/content/training/'+sorted(os.listdir(r'/content/training'))[100],'r')['array']) # 0, 50, 100\n",
    "\n",
    "f_mov_array = np.moveaxis((f),-1,1) # to shape(288, 8, 495, 436)\n",
    "\n",
    "f_v = f_mov_array[:,[0,2,4,6],:,:] # index by volume\n",
    "f_s = f_mov_array[:,[1,3,5,7],:,:] # index by speed\n",
    "\n",
    "m = nn.MaxPool2d((7, 6)) \n",
    "\n",
    "# Max volume\n",
    "f_v = torch.from_numpy(f_v).float() # numpy to torch\n",
    "output_v = m(f_v) # to shape(288, 4, 70, 72)\n",
    "\n",
    "# Max (0,Min(speed))\n",
    "f_s = torch.from_numpy(f_s).float() # numpy to torch\n",
    "f_s = f_s.where(f_s!=0, torch.tensor(256.0)) * (-1)\n",
    "output_s = m(f_s) * (-1) # to shape(288, 4, 70, 72)\n",
    "output_s = output_s.where(output_s!=256, torch.tensor(0.0))\n",
    "\n",
    "output_v = np.moveaxis(output_v.numpy(),1,-1) \n",
    "output_s = np.moveaxis(output_s.numpy(),1,-1) \n",
    "train_data = np.concatenate((output_v,output_s),axis=-1) # to shape(288, 70, 72, 8)\n",
    "\n",
    "type(train_data),train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 274459,
     "status": "ok",
     "timestamp": 1651100281603,
     "user": {
      "displayName": "Shiyuan Wang",
      "userId": "08549609244146929949"
     },
     "user_tz": 300
    },
    "id": "UX9mEHdIti7s",
    "outputId": "a636890d-d6b5-41b2-ed65-f1dd12967497"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [04:34<00:00,  5.59s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14400, 70, 72, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for filename in tqdm(sorted(os.listdir(r'/content/training'))[1:150]): # extract files from 2019-01-03 -- 2019-05-31 [1:150] #1:50, 51:100 101:150\n",
    "  # extract the date\n",
    "  train_file.append(filename[:10]) \n",
    "  # extract matrice and change the resolution\n",
    "  f = np.array(h5py.File('/content/training/'+filename,'r')['array'])\n",
    "\n",
    "  f_mov_array = np.moveaxis((f),-1,1) # to shape(288, 8, 495, 436)\n",
    "\n",
    "  f_v = f_mov_array[:,[0,2,4,6],:,:] # index by volume\n",
    "  f_s = f_mov_array[:,[1,3,5,7],:,:] # index by speed\n",
    "\n",
    "  m = nn.MaxPool2d((7, 6)) \n",
    "\n",
    "  # Max volume\n",
    "  f_v = torch.from_numpy(f_v).float() # numpy to torch\n",
    "  output_v = m(f_v) # to shape(288, 4, 70, 72)\n",
    "\n",
    "  # Max (0,Min(speed))\n",
    "  f_s = torch.from_numpy(f_s).float() # numpy to torch\n",
    "  f_s = f_s.where(f_s!=0, torch.tensor(256.0)) * (-1) # convert 0 to the smallest number -256\n",
    "  output_s = m(f_s) * (-1) # to shape(288, 4, 70, 72)\n",
    "  output_s = output_s.where(output_s!=256, torch.tensor(0.0)) # convert 256 to 0\n",
    "\n",
    "  output_v = np.moveaxis(output_v.numpy(),1,-1) \n",
    "  output_s = np.moveaxis(output_s.numpy(),1,-1) \n",
    "  output_final = np.concatenate((output_v,output_s),axis=-1) # to shape(288, 70, 72, 8)\n",
    "  \n",
    "  train_data = np.concatenate((train_data,output_final))\n",
    "  # train_data = torch.from_numpy(train_data).float() # we want to numpy to torch when using, so no need to convert it to torch right now.\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rHbexNjVkL4B"
   },
   "outputs": [],
   "source": [
    "# write into h5 file\n",
    "file = h5py.File('Train_7072_3.h5','w')\n",
    "file.create_dataset('data', data = train_data)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSIGqtQyKzM8"
   },
   "outputs": [],
   "source": [
    "!mv Train_7072_3.h5 gdrive/MyDrive/CEE498_Project/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3LBbROVns7J"
   },
   "source": [
    "## Test data *2019-06-01 -- 2019-06-30*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5960,
     "status": "ok",
     "timestamp": 1651097701462,
     "user": {
      "displayName": "Shiyuan Wang",
      "userId": "08549609244146929949"
     },
     "user_tz": 300
    },
    "id": "YuoBcbBUgUn1",
    "outputId": "f7354374-e522-4ba7-ba18-9eb406893157"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (288, 70, 72, 8))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract file name from 2019-06-01\n",
    "test_file= [sorted(os.listdir(r'/content/training'))[150][:10]] \n",
    "\n",
    "# extract matrices from 2019-06-01\n",
    "f = np.array(h5py.File('/content/training/'+sorted(os.listdir(r'/content/training'))[150],'r')['array'])\n",
    "\n",
    "f_mov_array = np.moveaxis((f),-1,1) # to shape(288, 8, 495, 436)\n",
    "\n",
    "f_v = f_mov_array[:,[0,2,4,6],:,:] # index by volume\n",
    "f_s = f_mov_array[:,[1,3,5,7],:,:] # index by speed\n",
    "\n",
    "m = nn.MaxPool2d((7,6)) \n",
    "\n",
    "# Max volume\n",
    "f_v = torch.from_numpy(f_v).float() # numpy to torch\n",
    "output_v = m(f_v) # to shape(288, 4, 70, 72)\n",
    "\n",
    "# Max (0,Min(speed))\n",
    "f_s = torch.from_numpy(f_s).float() # numpy to torch\n",
    "f_s = f_s.where(f_s!=0, torch.tensor(256.0)) * (-1)\n",
    "output_s = m(f_s) * (-1) # to shape(288, 4, 70, 72)\n",
    "output_s = output_s.where(output_s!=256, torch.tensor(0.0))\n",
    "\n",
    "output_v = np.moveaxis(output_v.numpy(),1,-1) \n",
    "output_s = np.moveaxis(output_s.numpy(),1,-1) \n",
    "test_data = np.concatenate((output_v,output_s),axis=-1) # to shape(288, 70, 72, 8)\n",
    "\n",
    "type(test_data),test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 144082,
     "status": "ok",
     "timestamp": 1651097851442,
     "user": {
      "displayName": "Shiyuan Wang",
      "userId": "08549609244146929949"
     },
     "user_tz": 300
    },
    "id": "evk6wUgagmjH",
    "outputId": "5f5caa80-f14d-490e-b26c-2fb24f071b60"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [02:23<00:00,  4.97s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8640, 70, 72, 8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for filename in tqdm(sorted(os.listdir(r'/content/training'))[151:180]): # extract files from 2019-06-02 -- 2019-06-30 \n",
    "  # extract the date\n",
    "  test_file.append(filename[:10]) \n",
    "  # extract matrice and change the resolution\n",
    "  f = np.array(h5py.File('/content/training/'+filename,'r')['array'])\n",
    "\n",
    "  f_mov_array = np.moveaxis((f),-1,1) # to shape(288, 8, 495, 436)\n",
    "\n",
    "  f_v = f_mov_array[:,[0,2,4,6],:,:] # index by volume\n",
    "  f_s = f_mov_array[:,[1,3,5,7],:,:] # index by speed\n",
    "\n",
    "  m = nn.MaxPool2d((7, 6)) \n",
    "\n",
    "  # Max volume\n",
    "  f_v = torch.from_numpy(f_v).float() # numpy to torch\n",
    "  output_v = m(f_v) # to shape(288, 4, 70, 72)\n",
    "\n",
    "  # Max (0,Min(speed))\n",
    "  f_s = torch.from_numpy(f_s).float() # numpy to torch\n",
    "  f_s = f_s.where(f_s!=0, torch.tensor(256.0)) * (-1) # convert 0 to the smallest number -256\n",
    "  output_s = m(f_s) * (-1) # to shape(288, 4, 70, 72)\n",
    "  output_s = output_s.where(output_s!=256, torch.tensor(0.0)) # convert 256 to 0\n",
    "\n",
    "  output_v = np.moveaxis(output_v.numpy(),1,-1) \n",
    "  output_s = np.moveaxis(output_s.numpy(),1,-1) \n",
    "  output_final = np.concatenate((output_v,output_s),axis=-1) # to shape(288, 70, 72, 8)\n",
    "  \n",
    "  test_data = np.concatenate((test_data,output_final))\n",
    "  # train_data = torch.from_numpy(test_data).float() # we want to numpy to torch when using, so no need to convert it to torch right now.\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohN12jOzkZnN"
   },
   "outputs": [],
   "source": [
    "# write into h5 file\n",
    "file = h5py.File('Test_7072.h5','w')\n",
    "file.create_dataset('data', data = test_data)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mTTyTOlQoovG"
   },
   "outputs": [],
   "source": [
    "!mv Train2.h5 gdrive/MyDrive/CEE498_Project/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Data_Process.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
